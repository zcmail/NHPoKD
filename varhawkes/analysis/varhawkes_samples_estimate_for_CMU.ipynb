{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\project\\time_series\\var-hawkes-master-noise-nonparam-upload-github\\varhawkes\n",
      "\n",
      "Start time is:  2020-06-30 23:03:40.376645\n",
      "alpha2 is: -74.70026951582065\n",
      "sigma2 is: 0.007632482343811812\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import argparse\n",
    "import json\n",
    "import sys\n",
    "import os\n",
    "import torch\n",
    "import math\n",
    "import datetime\n",
    "\n",
    "o_path = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "print (o_path)\n",
    "sys.path.append(o_path)\n",
    "\n",
    "# Internal libraries\n",
    "import excitation_kernels\n",
    "import hawkes_model_single\n",
    "\n",
    "\n",
    "from make_data_for_samples import make_data \n",
    "from make_data_for_samples import make_data_all_expect \n",
    "from make_data_for_estimate import make_estimate_data\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "global result\n",
    "\n",
    "def make_object(module, name, args):\n",
    "    return getattr(module, name)(**args)\n",
    "\n",
    "param_dict_exitation = {'exitation': {'name': 'MixtureGaussianFilter','args': {'M': 11, \"end_time\": 36, 'cut_off': 1000.0}}}\n",
    "\n",
    "\n",
    "#positive samples\n",
    "def decision_fun_1(mu,W, new_events, M ,param_dict, alpha, sigma, threshold):\n",
    "    events_num = len(new_events)\n",
    "    dim = len(new_events[0])\n",
    "    n_params = dim * (M * dim + 1)\n",
    "    #3倍上界\n",
    "    up =  math.exp(alpha) * (math.exp(sigma))**3\n",
    "    #3倍下界\n",
    "    down = math.exp(alpha) / (math.exp(sigma))**3    \n",
    "    \n",
    "    # Init Hawkes process model object\n",
    "    excitation_obj = make_object(excitation_kernels, **param_dict['exitation'])\n",
    "    hawkes_model_obj = hawkes_model_single.HawkesModel(excitation=excitation_obj, verbose=False)\n",
    "   \n",
    "    W = W.view(dim,dim,M)\n",
    "    \n",
    "    count = 0\n",
    "    \n",
    "    loglik_all=[]\n",
    "\n",
    "    for i in range(events_num):\n",
    "        loglik=[0.0,0.0]        \n",
    "        hawkes_model_obj.set_data(new_events[i])\n",
    "        loglik_max = hawkes_model_obj.log_likelihood(mu,W,distb=up)\n",
    "        loglik_min = hawkes_model_obj.log_likelihood(mu,W,distb=down)\n",
    "        \n",
    "        loglik[0] = loglik_min.item()\n",
    "        loglik[1] = loglik_max.item()\n",
    "        \n",
    "        if math.isnan(loglik[0]):\n",
    "            if i ==0:\n",
    "                loglik[0] = loglik[1]\n",
    "            else:\n",
    "                loglik[0] = loglik_all[i-1][0]    \n",
    "        if math.isnan(loglik[1]):\n",
    "            if i ==0 :     #处理s032第一个就出现nan的情况\n",
    "                loglik[1] = loglik[0]\n",
    "            else:\n",
    "                loglik[1] = loglik_all[i-1][1]\n",
    "        \n",
    "        loglik_all.append(loglik)\n",
    "        \n",
    "    loglik_list = sum(loglik_all,[])\n",
    "    #print(loglik_list)\n",
    "    \n",
    "    mean = np.mean(loglik_list)\n",
    "    print('mean:',mean)\n",
    "    \n",
    "    loglik_list_sort =  sorted(loglik_list)     \n",
    "    \n",
    "    mean = np.mean(loglik_list_sort[19:380])\n",
    "    print('mean after outlier del:',mean)\n",
    "    \n",
    "    distance = list( map(lambda x: abs(x - mean), loglik_list) )\n",
    "    \n",
    "    distance_array = np.array(distance)\n",
    "    #距离大于threshold的正样本个数\n",
    "    out_num = np.sum((distance_array > threshold))  \n",
    "    \n",
    "    return mean,out_num\n",
    "\n",
    "#all samples\n",
    "def decision_fun_2(mu,W, new_events, M ,param_dict, alpha, sigma,threshold, mean):\n",
    "    events_num = len(new_events)\n",
    "    dim = len(new_events[0])\n",
    "    n_params = dim * (M * dim + 1)\n",
    "    #3倍上界\n",
    "    up =  math.exp(alpha) * (math.exp(sigma))**3\n",
    "    #3倍下界\n",
    "    down = math.exp(alpha) / (math.exp(sigma))**3    \n",
    "    \n",
    "    # Init Hawkes process model object\n",
    "    excitation_obj = make_object(excitation_kernels, **param_dict['exitation'])\n",
    "    hawkes_model_obj = hawkes_model_single.HawkesModel(excitation=excitation_obj, verbose=False)\n",
    "   \n",
    "    W = W.view(dim,dim,M)\n",
    "    \n",
    "    count = 0\n",
    "    \n",
    "    loglik_all=[]\n",
    "\n",
    "    for i in range(events_num):\n",
    "        loglik=[0.0,0.0]        \n",
    "        hawkes_model_obj.set_data(new_events[i])\n",
    "        loglik_max = hawkes_model_obj.log_likelihood(mu,W,distb=up)\n",
    "        loglik_min = hawkes_model_obj.log_likelihood(mu,W,distb=down)\n",
    "        \n",
    "        loglik[0] = loglik_min.item()\n",
    "        loglik[1] = loglik_max.item()\n",
    "        \n",
    "        if math.isnan(loglik[0]):\n",
    "            if i ==0:\n",
    "                loglik[0] = loglik[1]\n",
    "            else:\n",
    "                loglik[0] = loglik_all[i-1][0]   \n",
    "        if math.isnan(loglik[1]):\n",
    "            if i == 0 :     #处理s032第一个就出现nan的情况\n",
    "                loglik[1] = loglik[0]\n",
    "            else:\n",
    "                loglik[1] = loglik_all[i-1][1]\n",
    "            \n",
    "        loglik_all.append(loglik)\n",
    "        \n",
    "    loglik_list = sum(loglik_all,[])\n",
    "  \n",
    "    distance = list( map(lambda x: abs(x - mean), loglik_list) )\n",
    "    \n",
    "    distance_array = np.array(distance)\n",
    "\n",
    "    out_num = np.sum((distance_array > threshold))  \n",
    "    \n",
    "    return out_num\n",
    "\n",
    "def estimate(exp_dir, param_filename, stdout=None, stderr=None):\n",
    "    if stdout is not None:\n",
    "        sys.stdout = open(stdout, 'w')\n",
    "    if stderr is not None:\n",
    "        sys.stderr = open(stderr, 'w')\n",
    "    print('\\nStart time is: ', datetime.datetime.today())\n",
    "   \n",
    "    data_fileName = \"./data/DSL-StrongPasswordData.xls\"\n",
    "    \n",
    "    user = 's032'\n",
    "    \n",
    "    if user == 's036':\n",
    "        events = make_data('s036',12000,12400,data_fileName)\n",
    "    if user == 's047':\n",
    "        events = make_data('s047',16000,16400,data_fileName)\n",
    "    if user == 's052':\n",
    "        events = make_data('s052',18000,18400,data_fileName)\n",
    "    if user == 's032':\n",
    "        events = make_data('s032',10400,10800,data_fileName)\n",
    "    if user == 's010':\n",
    "        events = make_data('s010',2400,2800,data_fileName)\n",
    "    if user == 's008':\n",
    "        events = make_data('s008',2000,2400,data_fileName)\n",
    "    if user == 's007':\n",
    "        events = make_data('s007',1600,2000,data_fileName)\n",
    "    if user == 's005':\n",
    "        events = make_data('s005',1200,1600,data_fileName)\n",
    "    if user == 's004':\n",
    "        events = make_data('s004',800,1200,data_fileName)\n",
    "    if user == 's003':\n",
    "        events = make_data('s003',400,800,data_fileName)\n",
    "    if user == 's002':\n",
    "        events = make_data('s002',0,400,data_fileName)\n",
    "        \n",
    "    n_jumps_per_dim = list(map(len, events[0]))\n",
    "    n_nodes = len(events[0])\n",
    "    #print('Number of jumps:', len(events)*sum(n_jumps_per_dim))\n",
    "    #print('per node:', n_jumps_per_dim)\n",
    "    \n",
    "    events = torch.tensor(events, dtype=torch.float32)\n",
    "    \n",
    "    #print('\\nestimating')\n",
    "    #print('=========')\n",
    "\n",
    "    param_filename = os.path.join(exp_dir, param_filename)\n",
    "    if not os.path.exists(param_filename):\n",
    "        raise FileNotFoundError(\n",
    "            'Input file `{:s}` not found.'.format(param_filename))\n",
    "    with open(param_filename, 'r') as param_file:\n",
    "        param_dict = json.load(param_file)\n",
    "        \n",
    "    mu = torch.tensor(param_dict['vi_exp']['mu'],dtype=torch.float32)\n",
    "    W = torch.tensor(param_dict['vi_exp']['adjacency'],dtype=torch.float32)    \n",
    "    alpha2 = param_dict['vi_exp']['alpha2'][0]\n",
    "    sigma2 = param_dict['vi_exp']['sigma2']\n",
    "    \n",
    "    print('alpha2 is:', alpha2)\n",
    "    print('sigma2 is:', sigma2)    \n",
    "\n",
    "    threshold_range = np.linspace(1,30,50)\n",
    "    FN = [0]*len(threshold_range)\n",
    "    TP = [0]*len(threshold_range)\n",
    "    FP = [0]*len(threshold_range)\n",
    "    TN = [0]*len(threshold_range)\n",
    "    \n",
    "    false_alarm_rate = [0.0]*len(threshold_range)\n",
    "    miss_rate = [0.0]*len(threshold_range)\n",
    "    recall = [0.0]*len(threshold_range)\n",
    "    precision = [0.0]*len(threshold_range)\n",
    "    #hit_rate = [0.0]*len(threshold_range)\n",
    "    \n",
    "    all_events = make_data_all_expect(data_fileName,user)\n",
    "    print('events num is:',len(all_events))\n",
    "    \n",
    "    all_events = torch.tensor(all_events, dtype=torch.float32)\n",
    "    \n",
    "    for i,threshold in enumerate(threshold_range):\n",
    "        print('threshold is:',threshold)\n",
    "        \n",
    "        mean,out_num = decision_fun_1(mu=mu, W=W, new_events=events, M=1 ,param_dict=param_dict_exitation,alpha=alpha2, sigma=sigma2,threshold=threshold)\n",
    "        out_num_all = decision_fun_2(mu=mu, W=W, new_events=all_events, M=1 ,param_dict=param_dict_exitation,alpha=alpha2, sigma=sigma2,\n",
    "                                     threshold=threshold, mean=mean)\n",
    "        \n",
    "        FN[i] = out_num\n",
    "        TP[i] = 800-out_num                         #400*2-out_num\n",
    "        FP[i] = 5000 -  out_num_all                 #2500*2 - out_num_all\n",
    "        TN[i] = out_num_all\n",
    "        \n",
    "        false_alarm_rate[i] = FP[i]/(FP[i]+TN[i])\n",
    "        miss_rate[i] = FN[i]/(TP[i]+FN[i])\n",
    "        recall[i] = TP[i]/(TP[i]+FN[i])\n",
    "        precision[i] = TP[i]/(TP[i]+FP[i])    \n",
    "    \n",
    "    print('FN is:', FN)\n",
    "    print('TP is:', TP)\n",
    "    print('FP is:', FP)\n",
    "    print('TN is:', TN)\n",
    "    \n",
    "    print('false_alarm_rate is:',false_alarm_rate)\n",
    "    print('miss_rate is:',miss_rate)\n",
    "    \n",
    "    #画false-alarm/hit rate ROC\n",
    "    hit_rate = list( map(lambda x: 1 - x, miss_rate) )\n",
    "    print('hit_rate is:',hit_rate)\n",
    "    plt.plot(false_alarm_rate,hit_rate,color=\"blue\",linewidth=1)\n",
    "    plt.plot(false_alarm_rate,false_alarm_rate,color=\"red\",linewidth=1)\n",
    "  \n",
    "    print('\\n\\nFinished.')\n",
    "    print('\\nEnd time is: ', datetime.datetime.today())\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('-d', '--dir', dest='dir', type=str,\n",
    "                        #required=True, help=\"Working directory\")\n",
    "                        required=False, default=\".\")\n",
    "    parser.add_argument('-p', '--params', dest='param_filename', type=str,\n",
    "                        required=False, default='params.json',\n",
    "                        help=\"Input parameter file (JSON)\")\n",
    "    args = parser.parse_known_args()[0]\n",
    "    estimate ('.','./result/50_train_fit_modify_prior/2/s032/s032_1.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
